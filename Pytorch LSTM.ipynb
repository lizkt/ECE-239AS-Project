{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### LSTM For EEG Data\n",
    "- First, import everything we're gonna be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "torch.manual_seed(1)\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class EEGLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, seq_len, input_dim, hidden_dim, output_dim = 4):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.bidirectional = True #TODO turn this into an arg\n",
    "        # components needed for our model\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, bidirectional = self.bidirectional)\n",
    "        # the result if bidirectional is 2x shape if not bidirectional, so account for that\n",
    "        self.linear = nn.Linear(self.hidden_dim * (2 if self.bidirectional else 1), self.output_dim)\n",
    "        self.hidden = self.init_hidden(self.hidden_dim)\n",
    "        \n",
    "        # hidden layer init\n",
    "    def init_hidden(self, hidden_dim):\n",
    "        \"\"\"Initialize the hidden state in self.hidden\n",
    "        Dimensions are num_layers * minibatch_size * hidden_dim\n",
    "        IMPORTANT: Re-initialize this when you want the RNN to forget data (such as training on a new series of timesteps)\n",
    "        Don't re-init when it's on the same series (because we want to build up the hidden state)\n",
    "        \"\"\"\n",
    "        # num_layers * num_directions, batch, hidden_dim\n",
    "        bidirectional_mult = 2 if self.bidirectional else 1\n",
    "        # hidden state and cell state\n",
    "        return (autograd.Variable(torch.zeros(1 * bidirectional_mult, 1, hidden_dim)),\n",
    "                autograd.Variable(torch.zeros(1 * bidirectional_mult, 1, hidden_dim)))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"forwards input through the model\"\"\"\n",
    "        # convert the input into something Pytorch can understand\n",
    "        input = autograd.Variable(torch.FloatTensor(input)).contiguous()\n",
    "        # LSTM expects 3-D input: dim of input is expected to be seq_len, batch size, input size\n",
    "        input = input.view(self.seq_len, 1, -1) # present the sequence seq_len timesteps at a time\n",
    "        lstm_out, self.hidden = self.lstm(input, self.hidden)\n",
    "        scores = self.linear(lstm_out.view(self.seq_len,-1))\n",
    "        return scores\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = EEGLSTM(1, 22, 20) # seq len, input dim, hidden dim\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 22, 1000)\n",
      "(288, 22, 1000)\n",
      "(288, 22, 1000)\n",
      "(288, 22, 1000)\n",
      "(288, 22, 1000)\n",
      "(288, 22, 1000)\n",
      "(288, 22, 1000)\n",
      "(288, 22, 1000)\n",
      "(288, 22, 1000)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "from load_data import EEGDataLoader\n",
    "data_loader = EEGDataLoader()\n",
    "X_train, y_train, X_test, y_test = data_loader.load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.476845622062683\n",
      "1.0996127128601074\n",
      "0.7458711862564087\n",
      "0.4147893488407135\n",
      "0.27285921573638916\n",
      "0.18419355154037476\n",
      "0.14836658537387848\n",
      "0.12103196978569031\n",
      "0.10580530762672424\n",
      "0.08083368092775345\n",
      "0.05115697532892227\n",
      "0.036622967571020126\n",
      "0.030976692214608192\n",
      "0.02742568589746952\n",
      "0.024691741913557053\n",
      "0.02246127463877201\n",
      "0.020584117621183395\n",
      "0.018965208902955055\n",
      "0.017018217593431473\n",
      "0.015842419117689133\n",
      "predicted: 2, actual: 2\n",
      "accumulated loss after 1k timesteps: 0.20862285360321403\n",
      "3.095686674118042\n",
      "0.7790340781211853\n",
      "0.36346057057380676\n",
      "0.1960281878709793\n",
      "0.12252863496541977\n",
      "0.08559642732143402\n",
      "0.06405099481344223\n",
      "0.04944218695163727\n",
      "0.0391489677131176\n",
      "0.032448623329401016\n",
      "0.027684466913342476\n",
      "0.02413717657327652\n",
      "0.02144536003470421\n",
      "0.019291086122393608\n",
      "0.017502667382359505\n",
      "0.015986794605851173\n",
      "0.014683661982417107\n",
      "0.013551094569265842\n",
      "0.01255781576037407\n",
      "0.011679879389703274\n",
      "predicted: 0, actual: 0\n",
      "accumulated loss after 1k timesteps: 0.13685374086815863\n",
      "0.21879401803016663\n",
      "0.06139751523733139\n",
      "0.03916012868285179\n",
      "0.030674045905470848\n",
      "0.025133736431598663\n",
      "0.021499132737517357\n",
      "0.018208419904112816\n",
      "0.01613101176917553\n",
      "0.014632297679781914\n",
      "0.013444188982248306\n",
      "0.012443959712982178\n",
      "0.011573909781873226\n",
      "0.010798496194183826\n",
      "0.010083542205393314\n",
      "0.009372892789542675\n",
      "0.008723728358745575\n",
      "0.00821762066334486\n",
      "0.007762247696518898\n",
      "0.007341531105339527\n",
      "0.006950326729565859\n",
      "predicted: 0, actual: 0\n",
      "accumulated loss after 1k timesteps: 0.022229135911911727\n",
      "4.799723148345947\n",
      "1.4550951719284058\n",
      "1.109622597694397\n",
      "0.8963223099708557\n",
      "0.7114396691322327\n",
      "0.5524876713752747\n",
      "0.41458234190940857\n",
      "0.31591248512268066\n",
      "0.2524443566799164\n",
      "0.20403212308883667\n",
      "0.1699700504541397\n",
      "0.1451922506093979\n",
      "0.12651777267456055\n",
      "0.11101076751947403\n",
      "0.09582245349884033\n",
      "0.08338057994842529\n",
      "0.07150738686323166\n",
      "0.061748143285512924\n",
      "0.054944660514593124\n",
      "0.04971383512020111\n",
      "predicted: 3, actual: 3\n",
      "accumulated loss after 1k timesteps: 0.4533360818885267\n",
      "2.0572707653045654\n",
      "0.6647455096244812\n",
      "0.285798043012619\n",
      "0.14819079637527466\n",
      "0.09559399634599686\n",
      "0.06968330591917038\n",
      "0.05434346944093704\n",
      "0.0442894846200943\n",
      "0.03722623735666275\n",
      "0.03199967369437218\n",
      "0.0279732383787632\n",
      "0.02477194555103779\n",
      "0.02216271311044693\n",
      "0.019993571564555168\n",
      "0.018161214888095856\n",
      "0.016592884436249733\n",
      "0.01523570530116558\n",
      "0.014050319790840149\n",
      "0.013006743043661118\n",
      "0.012081656605005264\n",
      "predicted: 1, actual: 1\n",
      "accumulated loss after 1k timesteps: 0.11800373444426805\n",
      "4.314866542816162\n",
      "0.22101269662380219\n",
      "0.08878404647111893\n",
      "0.05711323395371437\n",
      "0.04224720597267151\n",
      "0.03215731307864189\n",
      "0.026767071336507797\n",
      "0.022975243628025055\n",
      "0.02008531428873539\n",
      "0.01780708320438862\n",
      "0.015964709222316742\n",
      "0.01444287970662117\n",
      "0.013162886723876\n",
      "0.01206938736140728\n",
      "0.011122518219053745\n",
      "0.010292846709489822\n",
      "0.009558082558214664\n",
      "0.00890083983540535\n",
      "0.008307148702442646\n",
      "0.0077655259519815445\n",
      "predicted: 2, actual: 2\n",
      "accumulated loss after 1k timesteps: 0.06107919313386083\n",
      "0.7965598702430725\n",
      "0.04366159066557884\n",
      "0.026022154837846756\n",
      "0.020235750824213028\n",
      "0.016489241272211075\n",
      "0.01401040144264698\n",
      "0.012574102729558945\n"
     ]
    }
   ],
   "source": [
    "def train_seq():\n",
    "    for i in range(X_train.shape[0]):\n",
    "        for j in range(X_train.shape[1]):\n",
    "            label = y_train[i][j]\n",
    "            label = autograd.Variable(torch.LongTensor([int(label % 769)] * 1000))\n",
    "            sample = X_train[i][j]\n",
    "            if np.any(np.isnan(sample)):\n",
    "                print(\"skipping sample with NaN\")\n",
    "                continue\n",
    "            assert not np.any(np.isnan(sample))\n",
    "            model.zero_grad()\n",
    "            scores = model(sample)\n",
    "            loss = loss_function(scores, label)\n",
    "            loss.backward(retain_graph = True)\n",
    "            optimizer.step()\n",
    "             # clip the gradient to prevent exploding gradients (probably not needed)\n",
    "            nn.utils.clip_grad_norm(model.parameters(), 0.99)\n",
    "            print(loss.data[0])\n",
    "        break\n",
    "def train_one_by_one():\n",
    "    i, j = 0, 0\n",
    "    for i in range(X_train.shape[0]):\n",
    "        for j in range(X_train.shape[1]):\n",
    "            sample = X_train[i][j].T\n",
    "            label = y_train[i][j]\n",
    "            # hack: deal with NaN\n",
    "            if np.any(np.isnan(sample)):\n",
    "                print(\"skipping sample with NaN\")\n",
    "                continue\n",
    "            assert not np.any(np.isnan(sample))\n",
    "            label = autograd.Variable(torch.LongTensor([int(label % 769)]))\n",
    "#            model.hidden = model.init_hidden(20)\n",
    "            accumulated_loss = 0\n",
    "            # present the seq across 1k timesteps, building up the state one at a time\n",
    "            for k in range(sample.shape[0]):\n",
    "                model.zero_grad()\n",
    "                input = sample[0]\n",
    "                assert input.shape[0] == 22\n",
    "                scores = model(input)\n",
    "                loss = loss_function(scores, label)\n",
    "                accumulated_loss +=loss.data[0]\n",
    "                out = loss.backward(retain_graph = True)\n",
    "                optimizer.step()\n",
    "                # clip the gradient to prevent exploding gradients (probably not needed)\n",
    "                nn.utils.clip_grad_norm(model.parameters(), 0.99)\n",
    "                if k % 50 == 0: print(loss.data[0])\n",
    "            lastpred = np.argmax(scores.data.numpy().reshape(4))\n",
    "            print(\"predicted: {}, actual: {}\".format(lastpred, y_train[i][j] % 769))\n",
    "            print(\"accumulated loss after 1k timesteps: {}\".format(accumulated_loss/1000))\n",
    "\n",
    "\n",
    "train_one_by_one()\n",
    "#train_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 770\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 770\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 770\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 772\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 772\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 772\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 770\n",
      "last timestep prediction: 772\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 769\n",
      "last timestep prediction: 771\n",
      "last timestep prediction: 771\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-c472355feaa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mnans_exist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnans_exist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nan scores exist\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-2a469df7af2b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# present the sequence seq_len timesteps at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;31m# indexes of hiddens[0] before hiddens[1], while the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;31m# map will interleave them.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mIndexSelect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# else fall through and raise an error in Index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, index)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvanced_indexing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_advanced_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# prediction code\n",
    "cur_X, cur_y = X_train[0], y_train[0]\n",
    "preds = []\n",
    "for i in range(cur_X.shape[0]):\n",
    "    sample, label = cur_X[i].T, cur_y[i]\n",
    "    # present the sequence one at a time, getting a prediction at each timestep\n",
    "    # hack: deal with NaN\n",
    "    if np.any(np.isnan(sample)):\n",
    "        print(\"skipping sample with NaNs\")\n",
    "        continue\n",
    "    assert not np.any(np.isnan(sample))\n",
    "    model.init_hidden(20)\n",
    "    for i in range(sample.shape[0]):\n",
    "        input = sample[i]\n",
    "        scores = model(input)\n",
    "        nans_exist = np.any(np.isnan(scores.data))\n",
    "        assert not nans_exist, \"nan scores exist\"\n",
    "        predicted_label = np.argmax(scores.data)\n",
    "    print(\"last timestep prediction: {}\".format(predicted_label + 769))\n",
    "    preds.append(predicted_label + 769)\n",
    "diffs = [1 if pred != label else 0 for pred, label in enumerate(preds, list(cur_y))]\n",
    "assert len(diffs) == 238\n",
    "errs = sum(diffs)\n",
    "print(errs/len(diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
