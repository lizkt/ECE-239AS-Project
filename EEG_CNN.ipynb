{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import h5py\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "deep = True\n",
    "if deep:\n",
    "    from DEEP_ECE_CNN import CNN\n",
    "else:\n",
    "    from SHALLOW_ECE_CNN import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 22, 1000)\n",
      "(288, 22, 1000)\n",
      "(288, 22, 1000)\n",
      "(288, 22, 1000)\n",
      "(288, 22, 1000)\n",
      "(288, 22, 1000)\n",
      "(288, 22, 1000)\n",
      "(288, 22, 1000)\n",
      "(288, 22, 1000)\n"
     ]
    }
   ],
   "source": [
    "#Load in the data\n",
    "from load_data import EEGDataLoader\n",
    "data = EEGDataLoader('project_datasets/')\n",
    "X_train, y_train, X_test, y_test =  data.load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the CNN\n",
    "cuda = False\n",
    "if torch.cuda.is_available():\n",
    "    cuda = True\n",
    "def CNN_init(lr):\n",
    "    cnn = CNN()\n",
    "    if torch.cuda.is_available():\n",
    "        cnn.cuda()\n",
    "        cnn = torch.nn.DataParallel(cnn,device_ids=range(torch.cuda.device_count()))\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    lr = lr\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(),lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    return cnn, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(cnn, X_train, y_train, epoch, batch_size, cuda, optimizer, criterion,X_test,y_test):\n",
    "    X_train_i, y_train_i = X_train[0], y_train[0]\n",
    "    show_acc = True\n",
    "    for epoch in range(epoch):\n",
    "        print('Epoch: ',epoch)\n",
    "        random = np.random.choice(X_train_i.shape[0],batch_size)#,replace=False)\n",
    "        iter = 0\n",
    "        for i in random:\n",
    "            image, label = X_train_i[i], y_train_i[i]\n",
    "            if np.any(np.isnan(image)):\n",
    "                continue\n",
    "            if cuda:\n",
    "                image = autograd.Variable(torch.cuda.FloatTensor(image.reshape((image.shape[0],1,image.shape[1]))))\n",
    "                label = autograd.Variable(torch.cuda.LongTensor([int(label %769)]))\n",
    "            else:\n",
    "                image = autograd.Variable(torch.FloatTensor(image.reshape((image.shape[0],1,image.shape[1]))))\n",
    "                label = autograd.Variable(torch.LongTensor([int(label %769)]))\n",
    "            optimizer.zero_grad()\n",
    "            scores = cnn(image)\n",
    "            scores = torch.mean(scores,0)\n",
    "            scores = scores.view(1,4)\n",
    "            loss = criterion(scores,label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if show_acc:\n",
    "            print('Train Accuracy: ',train_acc(cnn,X_train,y_train,cuda,optimizer))\n",
    "            print('Test Accuracy: ',test(cnn,X_test,y_test,cuda,optimizer))\n",
    "       # print('Loss: ',loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Accuracy\n",
    "def train_acc(cnn, X_train, y_train, cuda, optimizer):\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    X_train_i, y_train_i = X_train[0], y_train[0]\n",
    "    for i in range(X_train_i.shape[0]):\n",
    "        image, label = X_train_i[i], y_train_i[i]\n",
    "        if np.any(np.isnan(image)):\n",
    "            continue\n",
    "        if cuda:\n",
    "            image = autograd.Variable(torch.cuda.FloatTensor(image.reshape((image.shape[0],1,image.shape[1]))))\n",
    "            label = autograd.Variable(torch.cuda.LongTensor([int(label %769)]))\n",
    "        else:\n",
    "            image = autograd.Variable(torch.FloatTensor(image.reshape((image.shape[0],1,image.shape[1]))))\n",
    "            label = autograd.Variable(torch.LongTensor([int(label %769)]))\n",
    "        optimizer.zero_grad()\n",
    "        scores = cnn(image)\n",
    "        scores = torch.mean(scores,0)\n",
    "        scores = scores.view(1,4)\n",
    "        prediction = np.argmax(scores.data.cpu().numpy())\n",
    "        predictions.append(prediction)\n",
    "        labels.append(int(label%769))\n",
    "    diffs = [1 if prediction != label else 0 for prediction, label in zip(predictions, labels)]\n",
    "    error = sum(diffs)/len(diffs)\n",
    "    #print(\"accuracy: {}\".format(1 - error))\n",
    "    return (1 - error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Accuracy\n",
    "def test(cnn, X_test, y_test, cuda, optimizer):\n",
    "    X_test_i, y_test_i = X_test[0], y_test[0]\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for i in range(X_test_i.shape[0]):\n",
    "        image, label = X_test_i[i], y_test_i[i]\n",
    "        if np.any(np.isnan(image)):\n",
    "            continue\n",
    "        if cuda:\n",
    "            image = autograd.Variable(torch.cuda.FloatTensor(image.reshape((image.shape[0],1,image.shape[1]))))\n",
    "            label = autograd.Variable(torch.cuda.LongTensor([int(label %769)]))\n",
    "        else:\n",
    "            image = autograd.Variable(torch.FloatTensor(image.reshape((image.shape[0],1,image.shape[1]))))\n",
    "            label = autograd.Variable(torch.LongTensor([int(label %769)]))\n",
    "        optimizer.zero_grad()\n",
    "        scores = cnn(image)\n",
    "        scores = torch.mean(scores,0)\n",
    "        scores = scores.view(1,4)\n",
    "        prediction = np.argmax(scores.data.cpu().numpy())\n",
    "        predictions.append(prediction)\n",
    "        labels.append(int(label%769))\n",
    "\n",
    "\n",
    "    diffs = [1 if prediction != label else 0 for prediction, label in zip(predictions, labels)]\n",
    "    error = sum(diffs)/len(diffs)\n",
    "    #print(\"accuracy: {}\".format(1 - error))\n",
    "    return (1 - error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "ep = 40\n",
    "batch = 238\n",
    "cnn, opt, crit = CNN_init(lr)\n",
    "train(cnn, X_train, y_train, ep, batch, cuda, opt, crit,X_test,y_test)\n",
    "print('Learning Rate: ', lr, ' Batch Size: ', batch,' Epochs: ', ep)\n",
    "train_a = train_acc(cnn,X_train,y_train, cuda, opt)\n",
    "test_a = test(cnn,X_test,y_test, cuda, opt)\n",
    "print('Train: ', train_a, ' Test: ', test_a )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test a lot of shit\n",
    "learning_rates = np.array([0.1,5e-2,1e-2,5e-3,1e-3,5e-4,1e-4,5e-5,1e-5])\n",
    "batch_sizes = np.array([238,200,150,100,50])\n",
    "epochs = np.array([1,5,10,20,40])\n",
    "data = np.zeros((learning_rates.shape[0],batch_sizes.shape[0],epochs.shape[0],2))\n",
    "l = 0\n",
    "for lr in learning_rates:\n",
    "    b = 0\n",
    "    for batch in batch_sizes:\n",
    "        e = 0\n",
    "        prev_train = 0\n",
    "        for ep in epochs:\n",
    "            if prev_train == 1:\n",
    "                continue\n",
    "            cnn, opt, crit = CNN_init(lr)\n",
    "            train(cnn, X_train, y_train, ep, batch, cuda, opt, crit,X_test,y_test)\n",
    "            print('Learning Rate: ', lr, ' Batch Size: ', batch,' Epochs: ', ep)\n",
    "            train_a = train_acc(cnn,X_train,y_train, cuda, opt)\n",
    "            test_a = test(cnn,X_test,y_test, cuda, opt)\n",
    "            print('Train: ', train_a, ' Test: ', test_a )\n",
    "            data[l,b,e,0] = train_a\n",
    "            data[l,b,e,1] = test_a\n",
    "            prev_train = train_a\n",
    "            e += 1\n",
    "        b += 1\n",
    "    l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_crop(cnn, X_train, y_train, epoch, batch_size, cuda, optimizer, criterion):\n",
    "    X_train_i, y_train_i = X_train[0], y_train[0]\n",
    "    for epoch in range(epoch):\n",
    "        print('Epoch: ',epoch)\n",
    "        iter = 0\n",
    "        random = np.random.choice(X_train_i.shape[0],batch_size)\n",
    "        X_train_i = X_train[0][random]\n",
    "        for i in range(X_train_i.shape[0]):\n",
    "            image, label = X_train_i[i], y_train_i[i]\n",
    "            if np.any(np.isnan(image)):\n",
    "                    continue\n",
    "            for j in range(10):\n",
    "                lower = j*100\n",
    "                upper = (j+1)*100 - 1\n",
    "                image_c = image[:,lower:upper]\n",
    "                if cuda:\n",
    "                    image_c = autograd.Variable(torch.cuda.FloatTensor(image.reshape((image.shape[0],1,image.shape[1]))))\n",
    "                    label = autograd.Variable(torch.cuda.LongTensor([int(label %769)]))\n",
    "                else:\n",
    "                    image_c = autograd.Variable(torch.FloatTensor(image.reshape((image.shape[0],1,image.shape[1]))))\n",
    "                    label = autograd.Variable(torch.LongTensor([int(label %769)]))\n",
    "                optimizer.zero_grad()\n",
    "                scores = cnn(image_c)\n",
    "                scores = torch.mean(scores,0)\n",
    "                scores = scores.view(1,4)\n",
    "                loss = criterion(scores,label)\n",
    "                loss.backward()\n",
    "                optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_crop(cnn, X_train, y_train, cuda, optimizer):\n",
    "    X_train_i, y_train_i = X_train[0], y_train[0]\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    for i in range(X_train_i.shape[0]):\n",
    "        image, label = X_train_i[i], y_train_i[i]\n",
    "        if np.any(np.isnan(image)):\n",
    "                continue\n",
    "        scores_t = np.zeros(4)\n",
    "        if cuda:\n",
    "            scores_t = autograd.Variable(torch.cuda.FloatTensor(scores_t.reshape(1,4)))\n",
    "        else:\n",
    "            scores_t = autograd.Variable(torch.FloatTensor(scores_t.reshape(1,4)))\n",
    "        for j in range(10):\n",
    "            lower = j*100\n",
    "            upper = (j+1)*100 - 1\n",
    "            image_c = image[:,lower:upper]\n",
    "            if cuda:\n",
    "                image_c = autograd.Variable(torch.cuda.FloatTensor(image.reshape((image.shape[0],1,image.shape[1]))))\n",
    "                label = autograd.Variable(torch.cuda.LongTensor([int(label %769)]))\n",
    "            else:\n",
    "                image_c = autograd.Variable(torch.FloatTensor(image.reshape((image.shape[0],1,image.shape[1]))))\n",
    "                label = autograd.Variable(torch.LongTensor([int(label %769)]))\n",
    "            optimizer.zero_grad()\n",
    "            scores = cnn(image_c)\n",
    "            scores = torch.mean(scores,0)\n",
    "            scores = scores.view(1,4)\n",
    "            scores_t += scores\n",
    "        prediction = np.argmax(scores_t.data.cpu().numpy())\n",
    "        predictions.append(prediction)\n",
    "        labels.append(int(label%769))\n",
    "    diffs = [1 if prediction != label else 0 for prediction, label in zip(predictions, labels)]\n",
    "    error = sum(diffs)/len(diffs)\n",
    "    print(\"accuracy: {}\".format(1 - error))\n",
    "    return (1 - error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cropped\n",
    "lr = 0.001\n",
    "ep = 10\n",
    "batch = 150\n",
    "cnn, opt, crit = CNN_init(lr)\n",
    "train_crop(cnn, X_train, y_train, ep, batch, cuda, opt, crit)\n",
    "print('Learning Rate: ', lr, ' Batch Size: ', batch,' Epochs: ', ep)\n",
    "train_a = acc_crop(cnn,X_train,y_train, cuda, opt)\n",
    "test_a = acc_crop(cnn,X_test,y_test, cuda, opt)\n",
    "print('Train: ', train_a, ' Test: ', test_a )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a = acc_crop(cnn,X_train,y_train, cuda, opt)\n",
    "test_a = acc_crop(cnn,X_test,y_test, cuda, opt)\n",
    "print('Train: ', train_a, ' Test: ', test_a )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "#Initialize the CNN\n",
    "cnn = CNN()\n",
    "cuda = False\n",
    "if torch.cuda.is_available():\n",
    "    print('Using GPU')\n",
    "    cuda = True\n",
    "    cnn.cuda()\n",
    "    cnn = torch.nn.DataParallel(cnn,device_ids=range(torch.cuda.device_count()))\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "lr = 0.001\n",
    "epochs = 50\n",
    "batch_size = 150\n",
    "optimizer = torch.optim.Adam(cnn.parameters(),lr=lr)\n",
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Subject:  1\n",
      "Loss:  1.6033002138137817\n",
      "Subject:  2\n",
      "Loss:  1.5818686485290527\n",
      "Subject:  3\n",
      "Loss:  2.2883572578430176\n",
      "Subject:  4\n",
      "Loss:  1.5322730541229248\n",
      "Subject:  5\n",
      "Loss:  0.6604452729225159\n",
      "Subject:  6\n",
      "Loss:  1.0602604150772095\n",
      "Subject:  7\n",
      "Loss:  1.4509241580963135\n",
      "Subject:  8\n",
      "Loss:  1.8742921352386475\n",
      "Subject:  9\n",
      "Loss:  1.1256470680236816\n",
      "Epoch:  1\n",
      "Subject:  1\n",
      "Loss:  1.2024261951446533\n",
      "Subject:  2\n",
      "Loss:  0.9311540126800537\n",
      "Subject:  3\n",
      "Loss:  1.5646218061447144\n",
      "Subject:  4\n",
      "Loss:  1.7788896560668945\n",
      "Subject:  5\n",
      "Loss:  1.184976577758789\n",
      "Subject:  6\n",
      "Loss:  1.1306202411651611\n",
      "Subject:  7\n",
      "Loss:  1.100861668586731\n",
      "Subject:  8\n",
      "Loss:  1.4377527236938477\n",
      "Subject:  9\n",
      "Loss:  1.3461034297943115\n",
      "Epoch:  2\n",
      "Subject:  1\n",
      "Loss:  1.490314245223999\n",
      "Subject:  2\n",
      "Loss:  1.1507220268249512\n",
      "Subject:  3\n",
      "Loss:  1.3347386121749878\n",
      "Subject:  4\n",
      "Loss:  1.8304784297943115\n",
      "Subject:  5\n",
      "Loss:  0.9821665287017822\n",
      "Subject:  6\n",
      "Loss:  1.0596559047698975\n",
      "Subject:  7\n",
      "Loss:  1.4140074253082275\n",
      "Subject:  8\n",
      "Loss:  1.843510627746582\n",
      "Subject:  9\n",
      "Loss:  1.2871131896972656\n",
      "Epoch:  3\n",
      "Subject:  1\n",
      "Loss:  1.3795865774154663\n",
      "Subject:  2\n",
      "Loss:  0.9756729602813721\n",
      "Subject:  3\n",
      "Loss:  1.1854255199432373\n",
      "Subject:  4\n",
      "Loss:  1.6253376007080078\n",
      "Subject:  5\n",
      "Loss:  1.0858745574951172\n",
      "Subject:  6\n",
      "Loss:  1.1629102230072021\n",
      "Subject:  7\n",
      "Loss:  1.3096468448638916\n",
      "Subject:  8\n",
      "Loss:  1.9340808391571045\n",
      "Subject:  9\n",
      "Loss:  1.4208269119262695\n",
      "Epoch:  4\n",
      "Subject:  1\n",
      "Loss:  1.9152262210845947\n",
      "Subject:  2\n",
      "Loss:  0.8556509017944336\n",
      "Subject:  3\n",
      "Loss:  1.2690380811691284\n",
      "Subject:  4\n",
      "Loss:  1.5491575002670288\n",
      "Subject:  5\n",
      "Loss:  0.9748501777648926\n",
      "Subject:  6\n",
      "Loss:  1.3056983947753906\n",
      "Subject:  7\n",
      "Loss:  1.4197269678115845\n",
      "Subject:  8\n",
      "Loss:  1.8930529356002808\n",
      "Subject:  9\n",
      "Loss:  1.0938349962234497\n",
      "Epoch:  5\n",
      "Subject:  1\n",
      "Loss:  1.7164297103881836\n",
      "Subject:  2\n",
      "Loss:  0.824123740196228\n",
      "Subject:  3\n",
      "Loss:  1.4306246042251587\n",
      "Subject:  4\n",
      "Loss:  1.8017946481704712\n",
      "Subject:  5\n",
      "Loss:  0.9927436709403992\n",
      "Subject:  6\n",
      "Loss:  1.2813092470169067\n",
      "Subject:  7\n",
      "Loss:  1.2827908992767334\n",
      "Subject:  8\n",
      "Loss:  1.8611749410629272\n",
      "Subject:  9\n",
      "Loss:  1.302964687347412\n",
      "Epoch:  6\n",
      "Subject:  1\n",
      "Loss:  2.048614978790283\n",
      "Subject:  2\n",
      "Loss:  0.8903785943984985\n",
      "Subject:  3\n",
      "Loss:  1.433965802192688\n",
      "Subject:  4\n",
      "Loss:  1.6412311792373657\n",
      "Subject:  5\n",
      "Loss:  0.9396349191665649\n",
      "Subject:  6\n",
      "Loss:  1.3737971782684326\n",
      "Subject:  7\n",
      "Loss:  1.3163996934890747\n",
      "Subject:  8\n",
      "Loss:  1.6585618257522583\n",
      "Subject:  9\n",
      "Loss:  1.5455178022384644\n",
      "Epoch:  7\n",
      "Subject:  1\n",
      "Loss:  1.7551568746566772\n",
      "Subject:  2\n",
      "Loss:  0.9314704537391663\n",
      "Subject:  3\n",
      "Loss:  1.4455499649047852\n",
      "Subject:  4\n",
      "Loss:  1.6045924425125122\n",
      "Subject:  5\n",
      "Loss:  0.8597209453582764\n",
      "Subject:  6\n",
      "Loss:  1.0323309898376465\n",
      "Subject:  7\n",
      "Loss:  1.2650343179702759\n",
      "Subject:  8\n",
      "Loss:  1.9755606651306152\n",
      "Subject:  9\n",
      "Loss:  1.2837512493133545\n",
      "Epoch:  8\n",
      "Subject:  1\n",
      "Loss:  1.9006249904632568\n",
      "Subject:  2\n",
      "Loss:  0.7814452648162842\n",
      "Subject:  3\n",
      "Loss:  1.4659476280212402\n",
      "Subject:  4\n",
      "Loss:  1.2403240203857422\n",
      "Subject:  5\n",
      "Loss:  0.7283040285110474\n",
      "Subject:  6\n",
      "Loss:  0.7752562165260315\n",
      "Subject:  7\n",
      "Loss:  1.4009310007095337\n",
      "Subject:  8\n",
      "Loss:  1.3669987916946411\n",
      "Subject:  9\n",
      "Loss:  1.2490004301071167\n",
      "Epoch:  9\n",
      "Subject:  1\n",
      "Loss:  1.7657852172851562\n",
      "Subject:  2\n",
      "Loss:  0.6550078988075256\n",
      "Subject:  3\n",
      "Loss:  1.5203602313995361\n",
      "Subject:  4\n",
      "Loss:  1.0162112712860107\n",
      "Subject:  5\n",
      "Loss:  0.7364726066589355\n",
      "Subject:  6\n",
      "Loss:  0.30618083477020264\n",
      "Subject:  7\n",
      "Loss:  1.1148325204849243\n",
      "Subject:  8\n",
      "Loss:  1.0583113431930542\n",
      "Subject:  9\n",
      "Loss:  1.445631742477417\n",
      "Epoch:  10\n",
      "Subject:  1\n",
      "Loss:  1.0065441131591797\n",
      "Subject:  2\n",
      "Loss:  0.67782062292099\n",
      "Subject:  3\n",
      "Loss:  1.4433403015136719\n",
      "Subject:  4\n",
      "Loss:  1.1672223806381226\n",
      "Subject:  5\n",
      "Loss:  0.6008919477462769\n",
      "Subject:  6\n",
      "Loss:  0.21652913093566895\n",
      "Subject:  7\n",
      "Loss:  1.420835256576538\n",
      "Subject:  8\n",
      "Loss:  0.5515338182449341\n",
      "Subject:  9\n",
      "Loss:  1.2530219554901123\n",
      "Epoch:  11\n",
      "Subject:  1\n",
      "Loss:  0.3602936267852783\n",
      "Subject:  2\n",
      "Loss:  0.697041392326355\n",
      "Subject:  3\n",
      "Loss:  0.85965895652771\n",
      "Subject:  4\n",
      "Loss:  0.5540863275527954\n",
      "Subject:  5\n",
      "Loss:  0.26052236557006836\n",
      "Subject:  6\n",
      "Loss:  0.17149949073791504\n",
      "Subject:  7\n",
      "Loss:  0.41542863845825195\n",
      "Subject:  8\n",
      "Loss:  0.1926412582397461\n",
      "Subject:  9\n",
      "Loss:  0.6973249316215515\n",
      "Epoch:  12\n",
      "Subject:  1\n",
      "Loss:  0.23347032070159912\n",
      "Subject:  2\n",
      "Loss:  0.3430790901184082\n",
      "Subject:  3\n",
      "Loss:  1.150854229927063\n",
      "Subject:  4\n",
      "Loss:  0.5242700576782227\n",
      "Subject:  5\n",
      "Loss:  0.19099712371826172\n",
      "Subject:  6\n",
      "Loss:  0.05843043327331543\n",
      "Subject:  7\n",
      "Loss:  0.48301541805267334\n",
      "Subject:  8\n",
      "Loss:  0.2748284339904785\n",
      "Subject:  9\n",
      "Loss:  0.9345456957817078\n",
      "Epoch:  13\n",
      "Subject:  1\n",
      "Loss:  0.0927128791809082\n",
      "Subject:  2\n",
      "Loss:  0.10727453231811523\n",
      "Subject:  3\n",
      "Loss:  0.16466033458709717\n",
      "Subject:  4\n",
      "Loss:  0.16413462162017822\n",
      "Subject:  5\n",
      "Loss:  0.06463217735290527\n",
      "Subject:  6\n",
      "Loss:  0.01840043067932129\n",
      "Subject:  7\n",
      "Loss:  0.14561092853546143\n",
      "Subject:  8\n",
      "Loss:  0.21159601211547852\n",
      "Subject:  9\n",
      "Loss:  0.3765009641647339\n",
      "Epoch:  14\n",
      "Subject:  1\n",
      "Loss:  0.18098020553588867\n",
      "Subject:  2\n",
      "Loss:  0.21569591760635376\n",
      "Subject:  3\n",
      "Loss:  0.09498441219329834\n",
      "Subject:  4\n",
      "Loss:  0.5756948590278625\n",
      "Subject:  5\n",
      "Loss:  0.4211447238922119\n",
      "Subject:  6\n",
      "Loss:  0.01264643669128418\n",
      "Subject:  7\n",
      "Loss:  0.009810447692871094\n",
      "Subject:  8\n",
      "Loss:  0.015943050384521484\n",
      "Subject:  9\n",
      "Loss:  0.5548005700111389\n",
      "Epoch:  15\n",
      "Subject:  1\n",
      "Loss:  0.015613079071044922\n",
      "Subject:  2\n",
      "Loss:  0.031725168228149414\n",
      "Subject:  3\n",
      "Loss:  0.2356739044189453\n",
      "Subject:  4\n",
      "Loss:  0.0524599552154541\n",
      "Subject:  5\n",
      "Loss:  0.010504722595214844\n",
      "Subject:  6\n",
      "Loss:  0.004302024841308594\n",
      "Subject:  7\n",
      "Loss:  0.018014907836914062\n",
      "Subject:  8\n",
      "Loss:  0.9756784439086914\n",
      "Subject:  9\n",
      "Loss:  0.07666611671447754\n",
      "Epoch:  16\n",
      "Subject:  1\n",
      "Loss:  0.10263752937316895\n",
      "Subject:  2\n",
      "Loss:  0.49545609951019287\n",
      "Subject:  3\n",
      "Loss:  0.11887907981872559\n",
      "Subject:  4\n",
      "Loss:  0.060820937156677246\n",
      "Subject:  5\n",
      "Loss:  0.00880289077758789\n",
      "Subject:  6\n",
      "Loss:  0.28730928897857666\n",
      "Subject:  7\n",
      "Loss:  0.005939483642578125\n",
      "Subject:  8\n",
      "Loss:  0.000232696533203125\n",
      "Subject:  9\n",
      "Loss:  2.904123067855835\n",
      "Epoch:  17\n",
      "Subject:  1\n",
      "Loss:  0.019954204559326172\n",
      "Subject:  2\n",
      "Loss:  0.03130936622619629\n",
      "Subject:  3\n",
      "Loss:  0.012863397598266602\n",
      "Subject:  4\n",
      "Loss:  0.0657339096069336\n",
      "Subject:  5\n",
      "Loss:  0.011209964752197266\n",
      "Subject:  6\n",
      "Loss:  0.04223752021789551\n",
      "Subject:  7\n",
      "Loss:  0.02031683921813965\n",
      "Subject:  8\n",
      "Loss:  0.008615493774414062\n",
      "Subject:  9\n",
      "Loss:  0.03785824775695801\n",
      "Epoch:  18\n",
      "Subject:  1\n",
      "Loss:  0.33000612258911133\n",
      "Subject:  2\n",
      "Loss:  0.28777480125427246\n",
      "Subject:  3\n",
      "Loss:  0.005429267883300781\n",
      "Subject:  4\n",
      "Loss:  0.027771472930908203\n",
      "Subject:  5\n",
      "Loss:  0.01500701904296875\n",
      "Subject:  6\n",
      "Loss:  1.4313793182373047\n",
      "Subject:  7\n",
      "Loss:  0.0006666183471679688\n",
      "Subject:  8\n",
      "Loss:  0.0030035972595214844\n",
      "Subject:  9\n",
      "Loss:  0.01738595962524414\n",
      "Epoch:  19\n",
      "Subject:  1\n",
      "Loss:  0.06454682350158691\n",
      "Subject:  2\n",
      "Loss:  0.0017232894897460938\n",
      "Subject:  3\n",
      "Loss:  0.013837337493896484\n",
      "Subject:  4\n",
      "Loss:  0.038925886154174805\n",
      "Subject:  5\n",
      "Loss:  0.007427215576171875\n",
      "Subject:  6\n",
      "Loss:  0.0005459785461425781\n",
      "Subject:  7\n",
      "Loss:  5.2928924560546875e-05\n",
      "Subject:  8\n",
      "Loss:  0.008242130279541016\n",
      "Subject:  9\n",
      "Loss:  0.12378513813018799\n",
      "Epoch:  20\n",
      "Subject:  1\n",
      "Loss:  0.00010633468627929688\n",
      "Subject:  2\n",
      "Loss:  0.01865696907043457\n",
      "Subject:  3\n",
      "Loss:  0.0014052391052246094\n",
      "Subject:  4\n",
      "Loss:  0.6698374152183533\n",
      "Subject:  5\n",
      "Loss:  0.0002651214599609375\n",
      "Subject:  6\n",
      "Loss:  0.026402950286865234\n",
      "Subject:  7\n",
      "Loss:  0.003109455108642578\n",
      "Subject:  8\n",
      "Loss:  0.2574629783630371\n",
      "Subject:  9\n",
      "Loss:  0.3387160897254944\n",
      "Epoch:  21\n",
      "Subject:  1\n",
      "Loss:  0.04177999496459961\n",
      "Subject:  2\n",
      "Loss:  1.1390349864959717\n",
      "Subject:  3\n",
      "Loss:  0.002559185028076172\n",
      "Subject:  4\n",
      "Loss:  0.000415802001953125\n",
      "Subject:  5\n",
      "Loss:  0.011383533477783203\n",
      "Subject:  6\n",
      "Loss:  0.060507774353027344\n",
      "Subject:  7\n",
      "Loss:  0.0003619194030761719\n",
      "Subject:  8\n",
      "Loss:  0.0010194778442382812\n",
      "Subject:  9\n",
      "Loss:  0.0008573532104492188\n",
      "Epoch:  22\n",
      "Subject:  1\n",
      "Loss:  0.0016160011291503906\n",
      "Subject:  2\n",
      "Loss:  8.58306884765625e-06\n",
      "Subject:  3\n",
      "Loss:  0.007355690002441406\n",
      "Subject:  4\n",
      "Loss:  0.0016083717346191406\n",
      "Subject:  5\n",
      "Loss:  0.0006933212280273438\n",
      "Subject:  6\n",
      "Loss:  0.0028667449951171875\n",
      "Subject:  7\n",
      "Loss:  1.9073486328125e-06\n",
      "Subject:  8\n",
      "Loss:  0.0031752586364746094\n",
      "Subject:  9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.31536662578582764\n",
      "Epoch:  23\n",
      "Subject:  1\n",
      "Loss:  0.3397812843322754\n",
      "Subject:  2\n",
      "Loss:  7.534027099609375e-05\n",
      "Subject:  3\n",
      "Loss:  0.0037322044372558594\n",
      "Subject:  4\n",
      "Loss:  0.043067216873168945\n",
      "Subject:  5\n",
      "Loss:  0.0002536773681640625\n",
      "Subject:  6\n",
      "Loss:  0.30431485176086426\n",
      "Subject:  7\n",
      "Loss:  0.00023794174194335938\n",
      "Subject:  8\n",
      "Loss:  0.01714944839477539\n",
      "Subject:  9\n",
      "Loss:  0.03368997573852539\n",
      "Epoch:  24\n",
      "Subject:  1\n",
      "Loss:  0.01490163803100586\n",
      "Subject:  2\n",
      "Loss:  9.5367431640625e-06\n",
      "Subject:  3\n",
      "Loss:  0.000152587890625\n",
      "Subject:  4\n",
      "Loss:  0.06446433067321777\n",
      "Subject:  5\n",
      "Loss:  0.003097057342529297\n",
      "Subject:  6\n",
      "Loss:  0.04683327674865723\n",
      "Subject:  7\n",
      "Loss:  0.0007491111755371094\n",
      "Subject:  8\n",
      "Loss:  0.00011157989501953125\n",
      "Subject:  9\n",
      "Loss:  0.07625389099121094\n",
      "Epoch:  25\n",
      "Subject:  1\n",
      "Loss:  0.0030546188354492188\n",
      "Subject:  2\n",
      "Loss:  0.000194549560546875\n",
      "Subject:  3\n",
      "Loss:  2.384185791015625e-05\n",
      "Subject:  4\n",
      "Loss:  0.007811307907104492\n",
      "Subject:  5\n",
      "Loss:  0.000919342041015625\n",
      "Subject:  6\n",
      "Loss:  0.0319828987121582\n",
      "Subject:  7\n",
      "Loss:  0.0015091896057128906\n",
      "Subject:  8\n",
      "Loss:  0.0003604888916015625\n",
      "Subject:  9\n",
      "Loss:  0.003281116485595703\n",
      "Epoch:  26\n",
      "Subject:  1\n",
      "Loss:  0.0050811767578125\n",
      "Subject:  2\n",
      "Loss:  0.20305585861206055\n",
      "Subject:  3\n",
      "Loss:  0.013604164123535156\n",
      "Subject:  4\n",
      "Loss:  0.0023894309997558594\n",
      "Subject:  5\n",
      "Loss:  0.005039215087890625\n",
      "Subject:  6\n",
      "Loss:  0.0024967193603515625\n",
      "Subject:  7\n",
      "Loss:  0.00138092041015625\n",
      "Subject:  8\n",
      "Loss:  0.01180410385131836\n",
      "Subject:  9\n",
      "Loss:  0.06825447082519531\n",
      "Epoch:  27\n",
      "Subject:  1\n",
      "Loss:  4.146821022033691\n",
      "Subject:  2\n",
      "Loss:  0.0014510154724121094\n",
      "Subject:  3\n",
      "Loss:  0.0017137527465820312\n",
      "Subject:  4\n",
      "Loss:  0.0019593238830566406\n",
      "Subject:  5\n",
      "Loss:  0.017714500427246094\n",
      "Subject:  6\n",
      "Loss:  0.0003838539123535156\n",
      "Subject:  7\n",
      "Loss:  0.021210670471191406\n",
      "Subject:  8\n",
      "Loss:  0.00016021728515625\n",
      "Subject:  9\n",
      "Loss:  0.008780956268310547\n",
      "Epoch:  28\n",
      "Subject:  1\n",
      "Loss:  9.5367431640625e-07\n",
      "Subject:  2\n",
      "Loss:  1.9073486328125e-06\n",
      "Subject:  3\n",
      "Loss:  0.0005555152893066406\n",
      "Subject:  4\n",
      "Loss:  0.01492166519165039\n",
      "Subject:  5\n",
      "Loss:  0.0011501312255859375\n",
      "Subject:  6\n",
      "Loss:  0.032225847244262695\n",
      "Subject:  7\n",
      "Loss:  1.9073486328125e-06\n",
      "Subject:  8\n",
      "Loss:  0.01597881317138672\n",
      "Subject:  9\n",
      "Loss:  0.014703750610351562\n",
      "Epoch:  29\n",
      "Subject:  1\n",
      "Loss:  2.09808349609375e-05\n",
      "Subject:  2\n",
      "Loss:  7.62939453125e-06\n",
      "Subject:  3\n",
      "Loss:  6.723403930664062e-05\n",
      "Subject:  4\n",
      "Loss:  0.014912843704223633\n",
      "Subject:  5\n",
      "Loss:  0.00026035308837890625\n",
      "Subject:  6\n",
      "Loss:  0.0003399848937988281\n",
      "Subject:  7\n",
      "Loss:  5.1975250244140625e-05\n",
      "Subject:  8\n",
      "Loss:  0.0029196739196777344\n",
      "Subject:  9\n",
      "Loss:  0.0360255241394043\n",
      "Epoch:  30\n",
      "Subject:  1\n",
      "Loss:  0.0005321502685546875\n",
      "Subject:  2\n",
      "Loss:  0.0024733543395996094\n",
      "Subject:  3\n",
      "Loss:  2.288818359375e-05\n",
      "Subject:  4\n",
      "Loss:  0.008327007293701172\n",
      "Subject:  5\n",
      "Loss:  0.03454399108886719\n",
      "Subject:  6\n",
      "Loss:  2.002716064453125e-05\n",
      "Subject:  7\n",
      "Loss:  0.09281086921691895\n",
      "Subject:  8\n",
      "Loss:  0.00966644287109375\n",
      "Subject:  9\n",
      "Loss:  0.018683433532714844\n",
      "Epoch:  31\n",
      "Subject:  1\n",
      "Loss:  2.86102294921875e-06\n",
      "Subject:  2\n",
      "Loss:  0.000576019287109375\n",
      "Subject:  3\n",
      "Loss:  8.58306884765625e-06\n",
      "Subject:  4\n",
      "Loss:  0.00014209747314453125\n",
      "Subject:  5\n",
      "Loss:  0.0030007362365722656\n",
      "Subject:  6\n",
      "Loss:  0.000507354736328125\n",
      "Subject:  7\n",
      "Loss:  0.0004730224609375\n",
      "Subject:  8\n",
      "Loss:  0.00019931793212890625\n",
      "Subject:  9\n",
      "Loss:  0.016783714294433594\n",
      "Epoch:  32\n",
      "Subject:  1\n",
      "Loss:  0.059001922607421875\n",
      "Subject:  2\n",
      "Loss:  0.0075473785400390625\n",
      "Subject:  3\n",
      "Loss:  0.022463321685791016\n",
      "Subject:  4\n",
      "Loss:  0.00035858154296875\n",
      "Subject:  5\n",
      "Loss:  0.00034999847412109375\n",
      "Subject:  6\n",
      "Loss:  0.007744789123535156\n",
      "Subject:  7\n",
      "Loss:  9.5367431640625e-07\n",
      "Subject:  8\n",
      "Loss:  0.000537872314453125\n",
      "Subject:  9\n",
      "Loss:  0.23790156841278076\n",
      "Epoch:  33\n",
      "Subject:  1\n",
      "Loss:  0.0003910064697265625\n",
      "Subject:  2\n",
      "Loss:  0.001983642578125\n",
      "Subject:  3\n",
      "Loss:  0.003429412841796875\n",
      "Subject:  4\n",
      "Loss:  0.0036153793334960938\n",
      "Subject:  5\n",
      "Loss:  0.12053394317626953\n",
      "Subject:  6\n",
      "Loss:  0.00051116943359375\n",
      "Subject:  7\n",
      "Loss:  9.5367431640625e-07\n",
      "Subject:  8\n",
      "Loss:  0.0719156265258789\n",
      "Subject:  9\n",
      "Loss:  0.03535795211791992\n",
      "Epoch:  34\n",
      "Subject:  1\n",
      "Loss:  0.014637470245361328\n",
      "Subject:  2\n",
      "Loss:  6.103515625e-05\n",
      "Subject:  3\n",
      "Loss:  0.0\n",
      "Subject:  4\n",
      "Loss:  0.00022268295288085938\n",
      "Subject:  5\n",
      "Loss:  4.291534423828125e-05\n",
      "Subject:  6\n",
      "Loss:  1.2419590950012207\n",
      "Subject:  7\n",
      "Loss:  0.0\n",
      "Subject:  8\n",
      "Loss:  0.13681888580322266\n",
      "Subject:  9\n",
      "Loss:  0.1394103765487671\n",
      "Epoch:  35\n",
      "Subject:  1\n",
      "Loss:  0.0018916130065917969\n",
      "Subject:  2\n",
      "Loss:  3.62396240234375e-05\n",
      "Subject:  3\n",
      "Loss:  2.288818359375e-05\n",
      "Subject:  4\n",
      "Loss:  0.539208173751831\n",
      "Subject:  5\n",
      "Loss:  2.574920654296875e-05\n",
      "Subject:  6\n",
      "Loss:  9.5367431640625e-07\n",
      "Subject:  7\n",
      "Loss:  2.86102294921875e-06\n",
      "Subject:  8\n",
      "Loss:  0.0035161972045898438\n",
      "Subject:  9\n",
      "Loss:  0.010067462921142578\n",
      "Epoch:  36\n",
      "Subject:  1\n",
      "Loss:  0.001514434814453125\n",
      "Subject:  2\n",
      "Loss:  0.0014467239379882812\n",
      "Subject:  3\n",
      "Loss:  0.0019125938415527344\n",
      "Subject:  4\n",
      "Loss:  8.7738037109375e-05\n",
      "Subject:  5\n",
      "Loss:  0.0014467239379882812\n",
      "Subject:  6\n",
      "Loss:  1.9073486328125e-06\n",
      "Subject:  7\n",
      "Loss:  0.014818191528320312\n",
      "Subject:  8\n",
      "Loss:  3.814697265625e-06\n",
      "Subject:  9\n",
      "Loss:  0.0026903152465820312\n",
      "Epoch:  37\n",
      "Subject:  1\n",
      "Loss:  0.06471967697143555\n",
      "Subject:  2\n",
      "Loss:  0.17647409439086914\n",
      "Subject:  3\n",
      "Loss:  0.0006933212280273438\n",
      "Subject:  4\n",
      "Loss:  0.0001544952392578125\n",
      "Subject:  5\n",
      "Loss:  0.00055694580078125\n",
      "Subject:  6\n",
      "Loss:  1.239776611328125e-05\n",
      "Subject:  7\n",
      "Loss:  0.000225067138671875\n",
      "Subject:  8\n",
      "Loss:  0.0021066665649414062\n",
      "Subject:  9\n",
      "Loss:  0.007502555847167969\n",
      "Epoch:  38\n",
      "Subject:  1\n",
      "Loss:  0.006066799163818359\n",
      "Subject:  2\n",
      "Loss:  0.0035567283630371094\n",
      "Subject:  3\n",
      "Loss:  0.0001373291015625\n",
      "Subject:  4\n",
      "Loss:  0.00048828125\n",
      "Subject:  5\n",
      "Loss:  0.0010976791381835938\n",
      "Subject:  6\n",
      "Loss:  2.86102294921875e-06\n",
      "Subject:  7\n",
      "Loss:  6.198883056640625e-05\n",
      "Subject:  8\n",
      "Loss:  6.418888092041016\n",
      "Subject:  9\n",
      "Loss:  0.4141533374786377\n",
      "Epoch:  39\n",
      "Subject:  1\n",
      "Loss:  0.000812530517578125\n",
      "Subject:  2\n",
      "Loss:  0.019704341888427734\n",
      "Subject:  3\n",
      "Loss:  9.5367431640625e-06\n",
      "Subject:  4\n",
      "Loss:  4.9591064453125e-05\n",
      "Subject:  5\n",
      "Loss:  1.19533109664917\n",
      "Subject:  6\n",
      "Loss:  0.0\n",
      "Subject:  7\n",
      "Loss:  2.6702880859375e-05\n",
      "Subject:  8\n",
      "Loss:  0.0\n",
      "Subject:  9\n",
      "Loss:  0.06912755966186523\n",
      "Epoch:  40\n",
      "Subject:  1\n",
      "Loss:  0.0021791458129882812\n",
      "Subject:  2\n",
      "Loss:  0.00027561187744140625\n",
      "Subject:  3\n",
      "Loss:  0.0010457038879394531\n",
      "Subject:  4\n",
      "Loss:  0.0022330284118652344\n",
      "Subject:  5\n",
      "Loss:  0.0\n",
      "Subject:  6\n",
      "Loss:  0.000186920166015625\n",
      "Subject:  7\n",
      "Loss:  5.7220458984375e-05\n",
      "Subject:  8\n",
      "Loss:  0.0\n",
      "Subject:  9\n",
      "Loss:  0.001262664794921875\n",
      "Epoch:  41\n",
      "Subject:  1\n",
      "Loss:  0.14443683624267578\n",
      "Subject:  2\n",
      "Loss:  7.62939453125e-06\n",
      "Subject:  3\n",
      "Loss:  7.43865966796875e-05\n",
      "Subject:  4\n",
      "Loss:  0.0\n",
      "Subject:  5\n",
      "Loss:  0.0\n",
      "Subject:  6\n",
      "Loss:  5.340576171875e-05\n",
      "Subject:  7\n",
      "Loss:  0.00048351287841796875\n",
      "Subject:  8\n",
      "Loss:  0.0\n",
      "Subject:  9\n",
      "Loss:  0.0005645751953125\n",
      "Epoch:  42\n",
      "Subject:  1\n",
      "Loss:  1.9073486328125e-05\n",
      "Subject:  2\n",
      "Loss:  0.0014209747314453125\n",
      "Subject:  3\n",
      "Loss:  6.4849853515625e-05\n",
      "Subject:  4\n",
      "Loss:  0.0021076202392578125\n",
      "Subject:  5\n",
      "Loss:  0.0\n",
      "Subject:  6\n",
      "Loss:  1.9073486328125e-06\n",
      "Subject:  7\n",
      "Loss:  9.5367431640625e-07\n",
      "Subject:  8\n",
      "Loss:  1.9073486328125e-06\n",
      "Subject:  9\n",
      "Loss:  0.0028839111328125\n",
      "Epoch:  43\n",
      "Subject:  1\n",
      "Loss:  0.0\n",
      "Subject:  2\n",
      "Loss:  0.001949310302734375\n",
      "Subject:  3\n",
      "Loss:  7.62939453125e-06\n",
      "Subject:  4\n",
      "Loss:  1.52587890625e-05\n",
      "Subject:  5\n",
      "Loss:  0.0\n",
      "Subject:  6\n",
      "Loss:  0.00014400482177734375\n",
      "Subject:  7\n",
      "Loss:  1.9073486328125e-06\n",
      "Subject:  8\n",
      "Loss:  0.0\n",
      "Subject:  9\n",
      "Loss:  0.0001354217529296875\n",
      "Epoch:  44\n",
      "Subject:  1\n",
      "Loss:  0.6091041564941406\n",
      "Subject:  2\n",
      "Loss:  0.0027284622192382812\n",
      "Subject:  3\n",
      "Loss:  3.814697265625e-06\n",
      "Subject:  4\n",
      "Loss:  0.00047016143798828125\n",
      "Subject:  5\n",
      "Loss:  0.0\n",
      "Subject:  6\n",
      "Loss:  0.0005893707275390625\n",
      "Subject:  7\n",
      "Loss:  0.0\n",
      "Subject:  8\n",
      "Loss:  8.0108642578125e-05\n",
      "Subject:  9\n",
      "Loss:  0.00478363037109375\n",
      "Epoch:  45\n",
      "Subject:  1\n",
      "Loss:  0.0\n",
      "Subject:  2\n",
      "Loss:  0.42174243927001953\n",
      "Subject:  3\n",
      "Loss:  0.00020313262939453125\n",
      "Subject:  4\n",
      "Loss:  0.004908084869384766\n",
      "Subject:  5\n",
      "Loss:  0.0\n",
      "Subject:  6\n",
      "Loss:  2.86102294921875e-06\n",
      "Subject:  7\n",
      "Loss:  0.017813682556152344\n",
      "Subject:  8\n",
      "Loss:  4.76837158203125e-06\n",
      "Subject:  9\n",
      "Loss:  0.00011348724365234375\n",
      "Epoch:  46\n",
      "Subject:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.7220458984375e-06\n",
      "Subject:  2\n",
      "Loss:  0.0\n",
      "Subject:  3\n",
      "Loss:  0.0029611587524414062\n",
      "Subject:  4\n",
      "Loss:  0.2381420135498047\n",
      "Subject:  5\n",
      "Loss:  0.0\n",
      "Subject:  6\n",
      "Loss:  0.0075836181640625\n",
      "Subject:  7\n",
      "Loss:  0.0008778572082519531\n",
      "Subject:  8\n",
      "Loss:  9.5367431640625e-07\n",
      "Subject:  9\n",
      "Loss:  5.7220458984375e-05\n",
      "Epoch:  47\n",
      "Subject:  1\n",
      "Loss:  0.0\n",
      "Subject:  2\n",
      "Loss:  0.0\n",
      "Subject:  3\n",
      "Loss:  2.09808349609375e-05\n",
      "Subject:  4\n",
      "Loss:  9.5367431640625e-06\n",
      "Subject:  5\n",
      "Loss:  9.5367431640625e-06\n",
      "Subject:  6\n",
      "Loss:  0.0\n",
      "Subject:  7\n",
      "Loss:  0.0018911361694335938\n",
      "Subject:  8\n",
      "Loss:  4.76837158203125e-06\n",
      "Subject:  9\n",
      "Loss:  0.04122018814086914\n",
      "Epoch:  48\n",
      "Subject:  1\n",
      "Loss:  1.239776611328125e-05\n",
      "Subject:  2\n",
      "Loss:  0.0\n",
      "Subject:  3\n",
      "Loss:  9.5367431640625e-07\n",
      "Subject:  4\n",
      "Loss:  8.58306884765625e-06\n",
      "Subject:  5\n",
      "Loss:  0.0\n",
      "Subject:  6\n",
      "Loss:  4.76837158203125e-06\n",
      "Subject:  7\n",
      "Loss:  0.0\n",
      "Subject:  8\n",
      "Loss:  0.00019359588623046875\n",
      "Subject:  9\n",
      "Loss:  0.002258777618408203\n",
      "Epoch:  49\n",
      "Subject:  1\n",
      "Loss:  1.9073486328125e-06\n",
      "Subject:  2\n",
      "Loss:  0.0\n",
      "Subject:  3\n",
      "Loss:  5.91278076171875e-05\n",
      "Subject:  4\n",
      "Loss:  3.62396240234375e-05\n",
      "Subject:  5\n",
      "Loss:  9.5367431640625e-07\n",
      "Subject:  6\n",
      "Loss:  1.239776611328125e-05\n",
      "Subject:  7\n",
      "Loss:  0.0\n",
      "Subject:  8\n",
      "Loss:  9.5367431640625e-07\n",
      "Subject:  9\n",
      "Loss:  1.268729567527771\n"
     ]
    }
   ],
   "source": [
    "#train the data on all subjects\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch: ',epoch)\n",
    "    for k in range(X_train.shape[0]):\n",
    "        X_train_i, y_train_i = X_train[k], y_train[k]\n",
    "        print('Subject: ', k+1)\n",
    "        for i in range(X_train_i.shape[0]):\n",
    "            image, label = X_train_i[i], y_train_i[i]\n",
    "            if np.any(np.isnan(image)):\n",
    "                continue\n",
    "            if cuda:\n",
    "                image = autograd.Variable(torch.cuda.FloatTensor(image.reshape((image.shape[0],1,image.shape[1]))))\n",
    "                label = autograd.Variable(torch.cuda.LongTensor([int(label %769)]))\n",
    "            else:\n",
    "                image = autograd.Variable(torch.FloatTensor(image.reshape((image.shape[0],1,image.shape[1]))))\n",
    "                label = autograd.Variable(torch.LongTensor([int(label %769)]))\n",
    "            optimizer.zero_grad()\n",
    "            scores = cnn(image)\n",
    "            scores = torch.mean(scores,0)\n",
    "            scores = scores.view(1,4)\n",
    "            loss = criterion(scores,label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Loss: ',loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject:  1\n",
      "accuracy: 0.9662447257383966\n",
      "Subject:  2\n",
      "accuracy: 0.9746300211416491\n",
      "Subject:  3\n",
      "accuracy: 0.9774330042313117\n",
      "Subject:  4\n",
      "accuracy: 0.9777777777777777\n",
      "Subject:  5\n",
      "accuracy: 0.9779661016949153\n",
      "Subject:  6\n",
      "accuracy: 0.9809187279151943\n",
      "Subject:  7\n",
      "accuracy: 0.9830611010284331\n",
      "Subject:  8\n",
      "accuracy: 0.9825119236883942\n",
      "Subject:  9\n",
      "accuracy: 0.9829867674858223\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "predictions = []\n",
    "labels = []\n",
    "for k in range(X_train.shape[0]):\n",
    "    X_train_i, y_train_i = X_train[k], y_train[k]\n",
    "    print('Subject: ', k+1)\n",
    "    for i in range(X_train_i.shape[0]):\n",
    "        image, label = X_train_i[i], y_train_i[i]\n",
    "        if np.any(np.isnan(image)):\n",
    "            continue\n",
    "        if cuda:\n",
    "            image = autograd.Variable(torch.cuda.FloatTensor(image.reshape((image.shape[0],1,image.shape[1]))))\n",
    "            label = autograd.Variable(torch.cuda.LongTensor([int(label %769)]))\n",
    "        else:\n",
    "            image = autograd.Variable(torch.FloatTensor(image.reshape((image.shape[0],1,image.shape[1]))))\n",
    "            label = autograd.Variable(torch.LongTensor([int(label %769)]))\n",
    "        optimizer.zero_grad()\n",
    "        scores = cnn(image)\n",
    "        scores = torch.mean(scores,0)\n",
    "        scores = scores.view(1,4)\n",
    "        prediction = np.argmax(scores.data.cpu().numpy())\n",
    "        predictions.append(prediction)\n",
    "        labels.append(int(label%769))\n",
    "    diffs = [1 if prediction != label else 0 for prediction, label in zip(predictions, labels)]\n",
    "    error = sum(diffs)/len(diffs)\n",
    "    print(\"accuracy: {}\".format(1 - error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject:  1\n",
      "accuracy: 0.4\n",
      "Subject:  2\n",
      "accuracy: 0.21999999999999997\n",
      "Subject:  3\n",
      "accuracy: 0.30000000000000004\n",
      "Subject:  4\n",
      "accuracy: 0.3125\n",
      "Subject:  5\n",
      "accuracy: 0.3829787234042553\n",
      "Subject:  6\n",
      "accuracy: 0.31999999999999995\n",
      "Subject:  7\n",
      "accuracy: 0.31999999999999995\n",
      "Subject:  8\n",
      "accuracy: 0.27083333333333337\n",
      "Subject:  9\n",
      "accuracy: 0.326530612244898\n"
     ]
    }
   ],
   "source": [
    "# Test Accuracy on all\n",
    "for k in range(X_test.shape[0]):\n",
    "    X_test_i, y_test_i = X_test[k], y_test[k]\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    print('Subject: ', k+1)\n",
    "    for i in range(X_test_i.shape[0]):\n",
    "        image, label = X_test_i[i], y_test_i[i]\n",
    "        if np.any(np.isnan(image)):\n",
    "            continue\n",
    "        if cuda:\n",
    "            image = autograd.Variable(torch.cuda.FloatTensor(image.reshape((image.shape[0],1,image.shape[1]))))\n",
    "            label = autograd.Variable(torch.cuda.LongTensor([int(label %769)]))\n",
    "        else:\n",
    "            image = autograd.Variable(torch.FloatTensor(image.reshape((image.shape[0],1,image.shape[1]))))\n",
    "            label = autograd.Variable(torch.LongTensor([int(label %769)]))\n",
    "        optimizer.zero_grad()\n",
    "        scores = cnn(image)\n",
    "        scores = torch.mean(scores,0)\n",
    "        scores = scores.view(1,4)\n",
    "        prediction = np.argmax(scores.data.cpu().numpy())\n",
    "        predictions.append(prediction)\n",
    "        labels.append(int(label%769))\n",
    "\n",
    "\n",
    "    diffs = [1 if prediction != label else 0 for prediction, label in zip(predictions, labels)]\n",
    "    error = sum(diffs)/len(diffs)\n",
    "    print(\"accuracy: {}\".format(1 - error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
